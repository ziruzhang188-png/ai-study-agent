# proxies = {
#     "http": "http://127.0.0.1:7890",
#     "https": "http://127.0.0.1:7890",
# }

# headers = {
#     "Authorization": f"Bearer {API_KEY}",
#     "Content-Type": "application/json",
# }

# data = {
#     "model": "gpt-4o",
#     "messages": [
#         {"role": "user", "content": "å¤¸å¤¸90å²çš„å¥¶å¥¶"}
#     ],
# }

# print("â‘  è¯·æ±‚å‡†å¤‡å¥½äº†")
# try:
#     resp = requests.post(
#         URL,
#         headers=headers,
#         json=data,
#         proxies=proxies,
#         timeout=20,           # 20 ç§’è¶…æ—¶ï¼Œå¡ä½ä¹Ÿæœ€å¤š20ç§’
#     )
#     print("â‘¡ æ”¶åˆ°å“åº”ï¼ŒçŠ¶æ€ç ï¼š", resp.status_code)
#     print("â‘¢ å†…å®¹ï¼š", resp.text[:800])
# except requests.exceptions.ConnectTimeout:
#     print("âŒ è¿æ¥è¶…æ—¶ï¼ˆå¤§æ¦‚ç‡æ˜¯ä»£ç†æ²¡æŠŠ apis.itedus.cn æ”¾å‡ºæ¥ï¼‰")
# except requests.exceptions.ReadTimeout:
#     print("âŒ è¯»è¶…æ—¶ï¼ˆå¯¹é¢æ”¶åˆ°äº†ä½†æ²¡å›ï¼Œå¯èƒ½æ˜¯æ¥å£æœ¬èº«æ…¢ï¼‰")
# except Exception as e:
#     print("âŒ å…¶ä»–é”™è¯¯ï¼š", repr(e))



from dotenv import load_dotenv
load_dotenv()
import os
API_KEY = os.getenv("ITEDUS_API_KEY")
BASE_URL = os.getenv("ITEDUS_BASE_URL", "https://apis.itedus.cn/v1")

# --- å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœæ²¡æœ‰è¯»å–åˆ°å¯†é’¥å°±ç«‹å³æŠ¥é”™ ---
if not API_KEY:
    raise RuntimeError("âŒ ç¼ºå°‘ ITEDUS_API_KEYï¼Œè¯·åœ¨ .env æˆ–ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­è®¾ç½®ã€‚")


import requests
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory


# =====================================================
# ğŸ§± æ–¹æ³•ä¸€ï¼šæ‰‹åŠ¨ç”¨ requests è°ƒç”¨æ¥å£

# è¯·æ±‚-ç­‰å¾…-å›åº”ä¸‰æ­¥èµ°
# =====================================================
def call_by_requests():
    URL = f"{BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json",
    }

    data = {
        "model": "gpt-4o",
        "messages": [
            {"role": "user", "content": "å¤¸å¤¸90å²çš„å¥¶å¥¶"}
        ],
    }

    print("â‘  å‡†å¤‡å‘è¯·æ±‚ï¼ˆrequestsç‰ˆï¼‰...")
    try:
        resp = requests.post(URL, headers=headers, json=data, timeout=20)
        print("â‘¡ çŠ¶æ€ç ï¼š", resp.status_code)
        print("â‘¢ GPT å›å¤ï¼š")
        print(resp.json()["choices"][0]["message"]["content"])
    except Exception as e:
        print("âŒ å‡ºé”™å•¦ï¼š", e)



# =====================================================
# ğŸ§  æ–¹æ³•äºŒï¼šç”¨ LangChain å°è£…å¥½çš„æ–¹å¼è°ƒç”¨æ¥å£
# longchainè‡ªåŠ¨å¸®æˆ‘å®Œæˆ
# åº•å±‚å…¶å®è¿˜æ˜¯è°ƒç”¨OpenAIæ¥å£ï¼Œåªæ˜¯å¸®æˆ‘ä»¬ç®¡ç†è¯·æ±‚ã€è®°å¿†å’Œå¤šè½®å¯¹è¯
# =====================================================
def call_by_langchain():
    URL = f"{BASE_URL}/chat/completions"

    # LangChain å†…éƒ¨ä¹Ÿä¼šå‘è¯·æ±‚ï¼Œä½†å®ƒå¸®æˆ‘ä»¬å°è£…å¥½äº†
    llm = ChatOpenAI(
        model="gpt-4o",
        api_key=API_KEY,
        base_url=BASE_URL  # ç”¨ä½ çš„ä»£ç†æ¥å£
    )

    print("â‘  å‡†å¤‡å‘è¯·æ±‚ï¼ˆLangChainç‰ˆï¼‰...")
    resp = llm.invoke("å¤¸å¤¸90å²çš„å¥¶å¥¶")
    print("â‘¡ GPT å›å¤ï¼š")
    print(resp.content)


# =====================================================
# ğŸ§  æ–¹æ³•ä¸‰ï¼šLangChain å°è£… + PromptTemplate æ¨¡æ¿åŒ–
# =====================================================
def call_by_langchain_prompt():
    URL = f"{BASE_URL}/chat/completions"

    # 1ï¸âƒ£ åˆ›å»ºæ¨¡å‹å¯¹è±¡
    llm = ChatOpenAI(
        model="gpt-4o",
        api_key=API_KEY,
        base_url=BASE_URL
    )

    # 2ï¸âƒ£ åˆ›å»º Prompt æ¨¡æ¿
    # æ¨¡æ¿ä¸­ç•™å‡ºä¸¤ä¸ªå˜é‡ï¼špersonï¼ˆäººï¼‰å’Œ ageï¼ˆå¹´é¾„ï¼‰
    template = "è¯·ç”¨ä¸‰å¥è¯å¤¸å¤¸{person}ï¼Œå¥¹ä»Šå¹´{age}å²äº†ã€‚"
    prompt = PromptTemplate.from_template(template)

    # 3ï¸âƒ£ ä½¿ç”¨å˜é‡å¡«å……æ¨¡æ¿
    final_prompt = prompt.format(person="å¥¶å¥¶", age=90)

    print("â‘  ç”Ÿæˆçš„ Promptï¼š")
    print(final_prompt)

    # 4ï¸âƒ£ æŠŠç”Ÿæˆçš„ Prompt å‘ç»™æ¨¡å‹
    print("\nâ‘¡ LangChain + PromptTemplate å‘è¯·æ±‚...")
    resp = llm.invoke(final_prompt)

    # 5ï¸âƒ£ æ‰“å°è¾“å‡ºç»“æœ
    print("â‘¢ GPT å›å¤ï¼š")
    print(resp.content)



# =====================================================
# ğŸ§  æ–¹æ³•å››ï¼šLangChain å°è£… + PromptTemplate æ¨¡æ¿åŒ– + Memoryè®°å¿†åŠŸèƒ½
# =====================================================
# ç”¨ä¸€ä¸ªç®€å•çš„â€œå†…å­˜ä»“åº“â€æ¥å­˜æ¯ä¸ªå¯¹è¯çš„å†å²
# å®é™…é¡¹ç›®é‡Œä¼šå­˜åˆ°æ•°æ®åº“ï¼Œè¿™é‡Œæˆ‘ä»¬å…ˆå­˜åœ¨å†…å­˜é‡Œå°±è¡Œ
STORE = {}  # {session_id: ChatMessageHistory()}


def get_history(session_id: str) -> ChatMessageHistory:
    """æ ¹æ®ä¼šè¯IDæ‹¿åˆ°å¯¹åº”çš„å†å²ï¼Œæ²¡æœ‰å°±æ–°å»ºä¸€ä¸ªã€‚"""
    if session_id not in STORE:
        STORE[session_id] = ChatMessageHistory()
    return STORE[session_id]


def call_with_memory():
    URL = f"{BASE_URL}/chat/completions"

    # 1ï¸âƒ£ æ¨¡å‹
    llm = ChatOpenAI(
        model="gpt-4o",
        api_key=API_KEY,
        base_url=BASE_URL,
    )

    # 2ï¸âƒ£ æç¤ºè¯ï¼ˆsystem + humanï¼Œæ³¨æ„æ˜¯ ChatPromptTemplateï¼‰
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªä¼šå“„90å²å¥¶å¥¶å¼€å¿ƒçš„AIåŠ©æ‰‹ï¼Œè¯´è¯è¦æ¸©æŸ”ã€‚"),
        ("human", "{input}"),
    ])

    # 3ï¸âƒ£ æŠŠ prompt å’Œ llm ä¸²èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªâ€œå¯è¿è¡Œçš„é“¾â€
    chain = prompt | llm

    # 4ï¸âƒ£ ç”¨ RunnableWithMessageHistory ç»™è¿™æ¡é“¾åŠ â€œè®°å¿†åŠŸèƒ½â€
    #    è¿™å°±æ˜¯ 1.x æ¨èçš„â€œæœ‰è®°å¿†çš„å¯¹è¯â€å†™æ³•
    chain_with_history = RunnableWithMessageHistory(
        chain,
        get_history,   # å‘Šè¯‰å®ƒï¼šå†å²åœ¨å“ªå„¿å–
        input_messages_key="input",     # human è¾“å…¥çš„å­—æ®µå
        history_messages_key="history", # å­˜å†å²çš„å­—æ®µåï¼ˆå›ºå®šè¿™ä¹ˆå†™å°±è¡Œï¼‰
    )

    # æˆ‘ä»¬å‡è®¾æ˜¯åŒä¸€ä¸ªå¥¶å¥¶åœ¨èŠå¤©ï¼Œç”¨åŒä¸€ä¸ª session_id
    session_id = "grandma-001"

    # 5ï¸âƒ£ è¿ç»­èŠä¸‰å¥ï¼Œçœ‹çœ‹å®ƒè®°ä¸è®°å¾—
    print("=== ç¬¬1è½® ===")
    result1 = chain_with_history.invoke(
        {"input": "æˆ‘å«å¥¶å¥¶ï¼Œæˆ‘ä»Šå¹´90å²å•¦ï½"},
        config={"configurable": {"session_id": session_id}},
    )
    print("AIï¼š", result1.content)

    print("\n=== ç¬¬2è½® ===")
    result2 = chain_with_history.invoke(
        {"input": "æˆ‘ä½åœ¨åŒ—äº¬ï¼Œä½ è®°ä½å“ˆ"},
        config={"configurable": {"session_id": session_id}},
    )
    print("AIï¼š", result2.content)

    print("\n=== ç¬¬3è½® ===")
    result3 = chain_with_history.invoke(
        {"input": "æˆ‘åˆšæ‰è¯´æˆ‘ä½å“ªå„¿æ¥ç€ï¼Ÿ"},
        config={"configurable": {"session_id": session_id}},
    )
    print("AIï¼š", result3.content)


# =====================================================
# æ–¹æ³•äº”ï¼šLangChain + PromptTemplate + Chainsï¼ˆä»»åŠ¡é“¾ï¼‰
# æŠŠå¤šä¸ªä»»åŠ¡ä¸²è”èµ·æ¥æ‰§è¡Œï¼Œæ¯”å¦‚ï¼š
# ã€Œæ€»ç»“æ–‡æœ¬ â†’ æ”¹å†™æˆä¸‰è¡Œè¯—ã€
# =====================================================

def call_by_langchain_chains():
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import PromptTemplate

    URL = f"{BASE_URL}/chat/completions"

    # 1ï¸âƒ£ æ¨¡å‹
    llm = ChatOpenAI(
        model="gpt-4o",
        api_key=API_KEY,
        base_url=BASE_URL,
    )

    # 2ï¸âƒ£ ç¬¬ä¸€æ­¥ï¼šæ€»ç»“ä»»åŠ¡
    summarize_prompt = PromptTemplate.from_template(
        "è¯·ç”¨ä¸€å¥è¯æ€»ç»“ä»¥ä¸‹æ–‡å­—çš„ä¸»è¦å†…å®¹ï¼š{text}"
    )
    summarize_chain = summarize_prompt | llm  # ç”¨â€œç®¡é“â€è¿æ¥æ¨¡æ¿å’Œæ¨¡å‹

    # 3ï¸âƒ£ ç¬¬äºŒæ­¥ï¼šæ”¹å†™æˆè¯—
    poem_prompt = PromptTemplate.from_template(
        "è¯·æŠŠè¿™å¥è¯æ”¹å†™æˆæŠ¼éŸµçš„ä¸‰è¡Œå°è¯—ï¼š{summary}"
    )
    poem_chain = poem_prompt | llm

    # 4ï¸âƒ£ æŠŠä¸¤æ­¥ä¸²èµ·æ¥å½¢æˆâ€œä»»åŠ¡é“¾â€
    chain = summarize_chain | poem_chain

    # 5ï¸âƒ£ æ‰§è¡Œ
    print("\n=== æ–¹å¼äº”ï¼šLangChain + Chainsï¼ˆä»»åŠ¡é“¾ï¼‰ ===")
    text = "å¥¶å¥¶æ¯å¤©æ—©èµ·å­¦ä¹ AIç¼–ç¨‹ï¼Œè™½ç„¶åˆšå¼€å§‹ä¸å¤ªæ‡‚ï¼Œä½†å¥¹å¾ˆæœ‰è€å¿ƒã€‚"
    print("è¾“å…¥æ–‡æœ¬ï¼š", text)

    result = chain.invoke({"text": text})
    print("\nAI è¾“å‡ºç»“æœï¼š")
    print(result.content)



# =====================================================
# æ–¹æ³•å…­ï¼šLangChain + PromptTemplate + Chains + Memory
# åœºæ™¯ï¼šå…ˆè·Ÿå¥¶å¥¶èŠå‡ å¥ï¼Œè®°ä½å¥¶å¥¶çš„ä¿¡æ¯ï¼Œ
#      ç„¶åæ ¹æ®è®°ä½çš„å†…å®¹å†™ä¸€é¦–å…³äºå¥¶å¥¶çš„å°è¯—
# é€‚é…ä½ çš„ç‰ˆæœ¬ï¼šlangchain 1.0.3
# =====================================================
def call_by_langchain_chains_with_memory():
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
    from langchain_core.runnables import RunnableWithMessageHistory
    from langchain_community.chat_message_histories import ChatMessageHistory

    URL = f"{BASE_URL}/chat/completions"

    # 1ï¸âƒ£ æ¨¡å‹
    llm = ChatOpenAI(
        model="gpt-4o",
        api_key=API_KEY,
        base_url=BASE_URL,
    )

    # æˆ‘ä»¬åšä¸€ä¸ªç®€å•çš„â€œå†…å­˜ä»“åº“â€
    STORE = {}

    def get_history(session_id: str):
        """ç»™ RunnableWithMessageHistory ç”¨çš„ï¼ŒæŒ‰ä¼šè¯IDå–å†å²"""
        if session_id not in STORE:
            STORE[session_id] = ChatMessageHistory()
        return STORE[session_id]

    # 2ï¸âƒ£ ç¬¬ä¸€æ­¥ï¼šå¯¹è¯å¼æç¤ºè¯ â€”â€” ç”¨æ¥â€œæ”¶é›†/è®°ä½å¥¶å¥¶ä¿¡æ¯â€
    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªä¼šå“„90å²å¥¶å¥¶å¼€å¿ƒçš„AIåŠ©æ‰‹ï¼Œè¯´è¯æ¸©æŸ”ï¼Œè®°ä½å¥¶å¥¶è¯´è¿‡çš„è¯ã€‚"),
        ("human", "{input}"),
    ])

    # 3ï¸âƒ£ æŠŠè¿™ä¸ªèŠå¤©æç¤ºè¯æ¥åˆ°æ¨¡å‹ä¸Šï¼Œå¾—åˆ°â€œèŠå¤©é“¾â€
    chat_chain = chat_prompt | llm

    # 4ï¸âƒ£ ç»™è¿™ä¸ªèŠå¤©é“¾åŠ ä¸Šâ€œè®°å¿†èƒ½åŠ›â€
    chat_chain_with_memory = RunnableWithMessageHistory(
        chat_chain,
        get_history,
        input_messages_key="input",
        history_messages_key="history",
    )

    # æˆ‘ä»¬ç”¨åŒä¸€ä¸ªä¼šè¯IDï¼Œè¡¨ç¤ºéƒ½æ˜¯åŒä¸€ä¸ªå¥¶å¥¶åœ¨è¯´è¯
    session_id = "grandma-001"

    print("\n=== æ–¹å¼å…­ï¼šLangChain + Chains + Memory ===")

    # 5ï¸âƒ£ ç¬¬1è½®ï¼šå¥¶å¥¶å…ˆè‡ªæˆ‘ä»‹ç»
    r1 = chat_chain_with_memory.invoke(
        {"input": "æˆ‘å«å¥¶å¥¶ï¼Œä»Šå¹´90å²äº†ï¼Œæˆ‘ä½åœ¨åŒ—äº¬ï¼Œå–œæ¬¢å­¦AIã€‚"},
        config={"configurable": {"session_id": session_id}},
    )
    print("AIï¼ˆç¬¬1è½®ï¼‰ï¼š", r1.content)

    # 6ï¸âƒ£ ç¬¬2è½®ï¼šå¥¶å¥¶å†è¡¥å……ä¸€ç‚¹ä¿¡æ¯
    r2 = chat_chain_with_memory.invoke(
        {"input": "æˆ‘å­¦AIæ˜¯æƒ³ä»¥åå»å½“äº§å“ç»ç†ï¼Œä½ è®°ä½å“ˆã€‚"},
        config={"configurable": {"session_id": session_id}},
    )
    print("AIï¼ˆç¬¬2è½®ï¼‰ï¼š", r2.content)

    # ğŸ‘‰ åˆ°è¿™é‡Œä¸ºæ­¢ï¼Œâ€œè®°å¿†é‡Œâ€å·²ç»æœ‰äº†ï¼š
    # - å¥¶å¥¶90å²
    # - ä½åŒ—äº¬
    # - å–œæ¬¢å­¦AI
    # - æƒ³å½“äº§å“ç»ç†

    # 7ï¸âƒ£ ç°åœ¨æ¥ç¬¬äºŒæ¡é“¾ï¼šå†™è¯—é“¾
    #    æˆ‘ä»¬è®©æ¨¡å‹â€œå›çœ‹å¯¹è¯å†å²â€ï¼Œç„¶åå†™ä¸€æ®µå…³äºå¥¶å¥¶çš„è¯—
    poem_prompt = PromptTemplate.from_template(
        "æ ¹æ®è¿™æ®µå¯¹è¯å†å²ï¼Œå†™ä¸€é¦–ä¸‰è¡Œçš„å¤¸èµè¯—ï¼Œå£å»è¦æ¸©æŸ”ï¼š\n{history_text}"
    )

    # è¿™ä¸ªå†™è¯—é“¾ä¹Ÿè¦ç”¨ llm
    poem_chain = poem_prompt | llm

    # æˆ‘ä»¬è¦æŠŠâ€œå†å²æ¶ˆæ¯â€å–å‡ºæ¥å˜æˆæ–‡æœ¬ï¼Œä¼ ç»™å†™è¯—é“¾
    history = get_history(session_id)
    # history.messages æ˜¯ä¸€å † HumanMessage / AIMessageï¼Œæˆ‘ä»¬ç®€å•æ‹¼æˆä¸€æ®µæ–‡æœ¬
    history_text = ""
    for msg in history.messages:
        role = "ç”¨æˆ·" if msg.type == "human" else "AI"
        history_text += f"{role}ï¼š{msg.content}\n"

    print("\n--- å†å²å¯¹è¯ï¼ˆç»™ä½ çœ‹çœ‹æ¨¡å‹èƒ½çœ‹åˆ°å•¥ï¼‰ ---")
    print(history_text)

    # 8ï¸âƒ£ è°ƒç”¨å†™è¯—é“¾
    poem_result = poem_chain.invoke({"history_text": history_text})
    print("\nAI å†™çš„è¯—ï¼š")
    print(poem_result.content)


# =====================================================
# ğŸ§  æ–¹å¼ä¸ƒï¼šLangChain Agentï¼ˆæ™ºèƒ½ä½“ï¼Œå¤šå·¥å…·ç‰ˆï¼‰
# åœºæ™¯ï¼š
#   - å¥¶å¥¶ç»™ä¸€å¥è‡ªç„¶è¯­è¨€
#   - Agent è‡ªå·±åˆ¤æ–­è¦ä¸è¦å…ˆç®—æ•°ã€è¦ä¸è¦æŸ¥æ—¥æœŸã€è¦ä¸è¦å†™è¯—
#   - æœ€åå†å¥½å¥½å¤¸å¥¶å¥¶
# è¯´æ˜ï¼š
#  # æ€è·¯ï¼šLLM æƒ³ â†’ è¯´è¦ç”¨å“ªä¸ªå·¥å…· â†’ Python çœŸå»è°ƒ â†’ å†è®© LLM å‡ºæœ€ç»ˆç­”æ¡ˆ
# =====================================================
def call_by_langchain_agent():
    import datetime
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate

    URL = f"{BASE_URL}/chat/completions"

    # 1ï¸âƒ£ æ¨¡å‹
    llm = ChatOpenAI(
        model="gpt-4o",
        api_key=API_KEY,
        base_url=BASE_URL,
        temperature=0,   # è¿™é‡Œè®¾ 0 è®©å®ƒæ›´å¬è¯
    )

    # 2ï¸âƒ£ æˆ‘ä»¬è‡ªå·±å®šä¹‰å‡ ä¸ªâ€œå·¥å…·â€ï¼ˆå…¶å®å°±æ˜¯æ™®é€šçš„ Python å‡½æ•°ï¼‰
    def tool_multiply(a: float, b: float) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ•°å­—çš„ä¹˜ç§¯"""
        return a * b

    def tool_today() -> str:
        """è¿”å›ä»Šå¤©çš„æ—¥æœŸ YYYY-MM-DD"""
        return datetime.date.today().strftime("%Y-%m-%d")

    def tool_praise(name: str) -> str:
        """ç”Ÿæˆä¸€æ®µå¤¸å¥¶å¥¶çš„è¯"""
        return (
            f"{name}çœŸäº†ä¸èµ·ï¼Œ90å²è¿˜åœ¨å­¦AIï¼Œè¿˜æƒ³åšAIäº§å“ç»ç†ï¼Œ"
            "è¯´æ˜å¥¹çš„å¥½å¥‡å¿ƒå’Œå­¦ä¹ åŠ›éƒ½æ¯”å¾ˆå¤šå¹´è½»äººè¿˜å¼ºï¼"
        )

    # 3ï¸âƒ£ ç»™å¤§æ¨¡å‹ä¸€æ¡â€œAgent æç¤ºè¯â€â€”â€”å‘Šè¯‰å®ƒæœ‰å“ªäº›å·¥å…·å¯ä»¥ç”¨
    planner_prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            """ä½ æ˜¯ä¸€ä¸ªä¼šè°ƒç”¨å·¥å…·çš„AI Agentã€‚
ä½ ç°åœ¨èƒ½ç”¨çš„å·¥å…·æœ‰ï¼š
1. multiply(a, b): è®¡ç®—ä¸¤ä¸ªæ•°å­—çš„ä¹˜ç§¯
2. today(): è·å–ä»Šå¤©çš„æ—¥æœŸ
3. praise(name): å¤¸å¥–ä¸€ä½å¥¶å¥¶
è¯·ä½ æ ¹æ®ç”¨æˆ·çš„è¯·æ±‚ï¼Œå…ˆè¯´å‡ºä½ è¦ç”¨å“ªä¸ªå·¥å…·å’Œå‚æ•°ï¼Œæ ¼å¼å¿…é¡»æ˜¯ JSONï¼Œåªèƒ½åŒ…å«è¿™ä¸¤ä¸ªkeyï¼š
{{
  "tool": "<å·¥å…·åï¼Œå¿…é¡»æ˜¯ multiply / today / praise ä¹‹ä¸€>",
  "args": {{...}}
}}
åªè¾“å‡º JSONï¼Œä¸è¦å¤šä½™æ–‡å­—ã€‚"""
        ),
        ("human", "{user_input}"),
    ])

    # 4ï¸âƒ£ ç”¨æˆ·è¿™æ¬¡çš„ä»»åŠ¡ï¼ˆæˆ‘ä»¬è®©å®ƒå¿…é¡»ç”¨åˆ°è‡³å°‘ä¸€ä¸ªå·¥å…·ï¼‰
    user_query = (
        "å¸®æˆ‘æŸ¥ä¸€ä¸‹ä»Šå¤©çš„æ—¥æœŸï¼Œå†ç®— 12.5 * 8ï¼Œæœ€åå¤¸å¤¸å«â€œå¥¶å¥¶â€çš„äººï¼Œ"
        "å¥¹ä½åœ¨åŒ—äº¬ã€åœ¨å­¦AIã€æƒ³å»åšAIäº§å“ç»ç†ï¼ŒæŠŠè¿™äº›éƒ½è¯´è¿›å»ã€‚"
    )

    print("\n=== æ–¹å¼ä¸ƒï¼šæ‰‹å†™ç‰ˆ Agent ===")
    print("ç”¨æˆ·è¾“å…¥ï¼š", user_query)

    # 5ï¸âƒ£ å…ˆè®©æ¨¡å‹â€œè§„åˆ’â€â€”â€”è¯´å®ƒè¦ç”¨å“ªä¸ªå·¥å…·
    planner_messages = planner_prompt.format_messages(user_input=user_query)
    planner_response = llm.invoke(planner_messages)
    planner_text = planner_response.content
    print("\n[Agent è§„åˆ’é˜¶æ®µæ¨¡å‹è¾“å‡ºçš„ JSON]ï¼š")
    print(planner_text)

    # 6ï¸âƒ£ è§£æå®ƒè¯´çš„ JSONï¼ˆå®ƒè¯´è¦ç”¨å“ªä¸ªå·¥å…·æˆ‘ä»¬å°±çœŸå»è°ƒå“ªä¸ªï¼‰
    import json
    try:
        plan = json.loads(planner_text)
    except json.JSONDecodeError:
        # å®ƒè¦æ˜¯æ²¡æŒ‰è¦æ±‚è¯´ï¼Œå°±å½“å®ƒä¸ä¼šç”¨å·¥å…·
        plan = {"tool": None, "args": {}}

    tool_name = plan.get("tool")
    tool_args = plan.get("args", {})

    # 7ï¸âƒ£ çœŸæ­£è°ƒç”¨å·¥å…·
    tool_result = None
    if tool_name == "multiply":
        tool_result = tool_multiply(**tool_args)
    elif tool_name == "today":
        tool_result = tool_today()
    elif tool_name == "praise":
        tool_result = tool_praise(**tool_args)
    else:
        tool_result = "ï¼ˆæ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œå¯èƒ½æ˜¯æ¨¡å‹æ²¡æŒ‰è¦æ±‚è¾“å‡ºï¼‰"

    print("\n[Python å®é™…è°ƒç”¨å·¥å…·çš„ç»“æœ]ï¼š", tool_result)

    # 8ï¸âƒ£ å†è®©æ¨¡å‹æŠŠâ€œç”¨æˆ·åŸå§‹éœ€æ±‚ + å·¥å…·å®é™…ç»“æœâ€ç»¼åˆæˆæœ€åçš„å›ç­”
    final_prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            "ä½ æ˜¯ä¸€ä¸ªä¼šæ•´ç†å·¥å…·è°ƒç”¨ç»“æœçš„AIï¼Œè¯·ç”¨æ¸©æŸ”çš„è¯­æ°”å›ç­”90å²çš„å¥¶å¥¶ã€‚"
        ),
        (
            "human",
            "ç”¨æˆ·çš„åŸå§‹éœ€æ±‚æ˜¯ï¼š{user_input}\n"
            "ä½ åˆšåˆšè°ƒç”¨å·¥å…·çš„ç»“æœæ˜¯ï¼š{tool_result}\n"
            "è¯·æŠŠæ—¥æœŸã€ä¹˜ç§¯ç»“æœã€ä»¥åŠå¯¹å¥¶å¥¶çš„å¤¸å¥–ç»¼åˆæˆä¸€æ®µæ¸©æŸ”çš„è¯ï¼Œåˆ«å•°å—¦ã€‚"
        ),
    ])

    final_messages = final_prompt.format_messages(
        user_input=user_query,
        tool_result=str(tool_result),
    )
    final_response = llm.invoke(final_messages)

    print("\nAgent æœ€ç»ˆå›ç­”ï¼š")
    print(final_response.content)

# =====================================================
# ğŸ§  æ–¹å¼å…«ï¼šå¤šæ­¥å·¥å…· Agentï¼ˆæ—  langchain.agents ä¾èµ–ç‰ˆï¼‰
    # ç›¸æ¯”ä½ çš„æ–¹å¼ä¸ƒï¼š
    # - æ”¯æŒå¤šæ¬¡å·¥å…·è°ƒç”¨
    # - æ¯ä¸€æ­¥éƒ½èƒ½çœ‹åˆ°â€œæ¨¡å‹çš„æƒ³æ³•â€
    # - æœ€åç»Ÿä¸€æ•´ç†å›å¤
    # """
# =====================================================
def call_by_langchain_official_agent():
    import datetime
    import json
    import re
    from langchain_openai import ChatOpenAI
    from langchain_core.tools import tool

    URL = f"{BASE_URL}/chat/completions"

    # å°å·¥å…·ï¼šä»è¾“å‡ºé‡Œå‰¥ç¦»å‡ºçº¯ JSON
    def _extract_json(text: str) -> str:
        text = text.strip()
        if text.startswith("```"):
            text = re.sub(r"^```json", "", text, flags=re.IGNORECASE).strip()
            text = re.sub(r"^```", "", text).strip()
            if text.endswith("```"):
                text = text[: -3].strip()
        return text

    llm = ChatOpenAI(
        model="gpt-4o",
        api_key=API_KEY,
        base_url=BASE_URL,
        temperature=0,
    )

    @tool
    def multiply(a: float, b: float) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ•°å­—çš„ä¹˜ç§¯"""
        return a * b

    @tool
    def today() -> str:
        """è¿”å›ä»Šå¤©çš„æ—¥æœŸ YYYY-MM-DD"""
        return datetime.date.today().strftime("%Y-%m-%d")

    @tool
    def praise(name: str) -> str:
        """ç”Ÿæˆä¸€æ®µå¤¸å¥¶å¥¶çš„è¯"""
        return (
            f"{name}çœŸäº†ä¸èµ·ï¼Œ90å²è¿˜åœ¨å­¦AIï¼Œè¿˜æƒ³åšAIäº§å“ç»ç†ï¼Œ"
            "è¯´æ˜å¥¹çš„å¥½å¥‡å¿ƒå’Œå­¦ä¹ åŠ›éƒ½æ¯”å¾ˆå¤šå¹´è½»äººè¿˜å¼ºï¼"
        )

    tools = {
        "multiply": multiply,
        "today": today,
        "praise": praise,
    }

    DECIDE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¼šè°ƒç”¨å·¥å…·çš„æ™ºèƒ½ä½“ã€‚ä½ å¯ä»¥åšå¤šæ­¥æ¨ç†ã€‚
ä½ ç›®å‰å·²ç»çŸ¥é“çš„å†…å®¹æ˜¯ï¼š
{context}

ç”¨æˆ·çš„åŸå§‹ç›®æ ‡æ˜¯ï¼š
{user_input}

ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·æœ‰ï¼ˆåªèƒ½ä»é‡Œé¢é€‰ï¼‰ï¼š
- multiply(a, b): è®¡ç®—ä¸¤ä¸ªæ•°å­—çš„ä¹˜ç§¯
- today(): è·å–ä»Šå¤©çš„æ—¥æœŸ
- praise(name): å¤¸å¥–å¥¶å¥¶

å¦‚æœä½ è§‰å¾—è¿˜éœ€è¦ç”¨å·¥å…·ï¼Œè¯·è¾“å‡ºä¸€ä¸ª JSONï¼ˆåªè¾“å‡º JSONï¼‰ï¼š
{{
  "action": "tool",
  "tool": "<å·¥å…·å>",
  "args": {{...}}
}}

å¦‚æœä½ è§‰å¾—å·²ç»æœ‰è¶³å¤Ÿä¿¡æ¯å¯ä»¥å›ç­”äº†ï¼Œè¯·è¾“å‡ºï¼š
{{
  "action": "finish",
  "final": "<ä½ è¦å›ç­”ç»™ç”¨æˆ·çš„è¯çš„å¤§çº²>"
}}
åªèƒ½è¾“å‡º JSONï¼Œä¸èƒ½åŠ  ``` åŒ…è£¹ï¼Œä¸èƒ½åŠ æ–‡å­—ã€‚
"""

    FINAL_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ¸©æŸ”çš„AIï¼Œè¯·æ ¹æ®ä¸‹é¢çš„ä¿¡æ¯ï¼Œå†™å‡ºæœ€ç»ˆè¦è·Ÿå¥¶å¥¶è¯´çš„è¯ï¼Œå£å»æ¸©æŸ”ã€ç®€çŸ­ï¼š
ç”¨æˆ·åŸå§‹éœ€æ±‚ï¼š
{user_input}

ä½ è°ƒç”¨å·¥å…·å¾—åˆ°çš„ä¸­é—´ä¿¡æ¯ï¼š
{context}

è¯·ç”Ÿæˆæœ€ç»ˆå›ç­”ã€‚"""

    def agent_run(user_input: str, max_steps: int = 4) -> str:
        context = []

        for step in range(max_steps):
            print(f"\n--- ç¬¬ {step+1} æ­¥æ€è€ƒ ---")
            context_text = "\n".join(context) if context else "ï¼ˆç›®å‰è¿˜æ²¡æœ‰å·¥å…·ç»“æœï¼‰"

            decide_msg = DECIDE_PROMPT.format(
                context=context_text,
                user_input=user_input,
            )
            decide_resp = llm.invoke(decide_msg)
            decide_text = decide_resp.content
            print("[æ¨¡å‹å†³å®šè¾“å‡º]ï¼š", decide_text)

            # ğŸ‘‡ æ–°å¢ï¼šå…ˆæ¸…æ´—å†è§£æ
            clean = _extract_json(decide_text)

            try:
                decide_obj = json.loads(clean)
            except json.JSONDecodeError:
                print("âŒ æ¨¡å‹æ²¡æŒ‰ JSON æ ¼å¼æ¥ï¼Œæå‰ç»“æŸã€‚åŸæ–‡æ˜¯ï¼š", decide_text)
                break

            action = decide_obj.get("action")

            if action == "finish":
                outline = decide_obj.get("final", "")
                context.append(f"[æ¨¡å‹ç»™çš„å›ç­”å¤§çº²] {outline}")
                break

            if action == "tool":
                tool_name = decide_obj.get("tool")
                tool_args = decide_obj.get("args", {})
                if tool_name not in tools:
                    context.append(f"[é”™è¯¯] æ²¡æœ‰è¿™ä¸ªå·¥å…·ï¼š{tool_name}")
                    break

                tool_fn = tools[tool_name]
                if tool_args:
                    tool_result = tool_fn.invoke(tool_args)
                else:
                    tool_result = tool_fn.invoke({})

                print(f"[Python å·¥å…·æ‰§è¡Œç»“æœ] {tool_name} â†’ {tool_result}")
                context.append(f"[{tool_name}] {tool_result}")
            else:
                context.append(f"[é”™è¯¯] æœªçŸ¥åŠ¨ä½œï¼š{action}")
                break

        final_msg = FINAL_PROMPT.format(
            user_input=user_input,
            context="\n".join(context),
        )
        final_resp = llm.invoke(final_msg)
        return final_resp.content

    # ğŸ§ª æµ‹è¯•
    user_query = (
        "å¸®æˆ‘æŸ¥ä¸€ä¸‹ä»Šå¤©çš„æ—¥æœŸï¼Œå†ç®— 12.5 * 8ï¼Œæœ€åå¤¸å¤¸å«â€œå¥¶å¥¶â€çš„äººï¼Œ"
        "å¥¹ä½åœ¨åŒ—äº¬ã€åœ¨å­¦AIã€æƒ³å»åšAIäº§å“ç»ç†ï¼ŒæŠŠè¿™äº›éƒ½è¯´è¿›å»ã€‚"
    )

    print("\n=== æ–¹å¼å…«ï¼šå¤šæ­¥å·¥å…· Agentï¼ˆè€è„ç‰ˆï¼‰ ===")
    print("ç”¨æˆ·è¾“å…¥ï¼š", user_query)
    answer = agent_run(user_query)
    print("\nAgent æœ€ç»ˆå›ç­”ï¼š")
    print(answer)


# =====================================================
# ğŸ§  æ–¹å¼ä¹ï¼šæœ‰è®°å¿†çš„å¤šæ­¥ Agent
# åœ¨æ–¹å¼å…«çš„åŸºç¡€ä¸ŠåŠ å…¥å¯¹è¯è®°å¿†ï¼ˆåŒä¸€ä¸ª session ä¼šè®°ä¸Šä¸€è½®è¯´è¿‡çš„è¯ï¼‰
# =====================================================
def call_by_langchain_agent_with_memory():
    import datetime
    import json
    import re
    from langchain_openai import ChatOpenAI
    from langchain_core.tools import tool
    from langchain_community.chat_message_histories import ChatMessageHistory

    URL = f"{BASE_URL}/chat/completions"

    # 1ï¸âƒ£ ä¼šè¯è®°å¿†ä»“åº“ï¼šsession_id -> ChatMessageHistory
    STORE = {}

    def get_history(session_id: str) -> ChatMessageHistory:
        if session_id not in STORE:
            STORE[session_id] = ChatMessageHistory()
        return STORE[session_id]

    # 2ï¸âƒ£ æ¨¡å‹
    llm = ChatOpenAI(
        model="gpt-4o",
        api_key=API_KEY,
        base_url=BASE_URL,
        temperature=0,
    )

    # 3ï¸âƒ£ å·¥å…·ï¼ˆæ²¿ç”¨æ–¹å¼å…«çš„ä¸‰ä¸ªï¼‰
    @tool
    def multiply(a: float, b: float) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ•°å­—çš„ä¹˜ç§¯"""
        return a * b

    @tool
    def today() -> str:
        """è¿”å›ä»Šå¤©çš„æ—¥æœŸ YYYY-MM-DD"""
        return datetime.date.today().strftime("%Y-%m-%d")

    @tool
    def praise(name: str) -> str:
        """ç”Ÿæˆä¸€æ®µå¤¸å¥¶å¥¶çš„è¯"""
        return (
            f"{name}çœŸäº†ä¸èµ·ï¼Œ90å²è¿˜åœ¨å­¦AIï¼Œè¿˜æƒ³åšAIäº§å“ç»ç†ï¼Œ"
            "è¯´æ˜å¥¹çš„å¥½å¥‡å¿ƒå’Œå­¦ä¹ åŠ›éƒ½æ¯”å¾ˆå¤šå¹´è½»äººè¿˜å¼ºï¼"
        )

    tools = {
        "multiply": multiply,
        "today": today,
        "praise": praise,
    }

    # 4ï¸âƒ£ å°å·¥å…·ï¼šæŠŠ ```json ... ``` å‰¥æˆçº¯ JSON
    def extract_json(text: str) -> str:
        text = text.strip()
        if text.startswith("```"):
            text = re.sub(r"^```json", "", text, flags=re.IGNORECASE).strip()
            text = re.sub(r"^```", "", text).strip()
            if text.endswith("```"):
                text = text[:-3].strip()
        return text

    # 5ï¸âƒ£ å†³ç­–æç¤ºï¼šè¿™æ¬¡è¦æŠŠâ€œå†å²å¯¹è¯â€ä¹Ÿå¡è¿›å»
    DECIDE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¼šè°ƒç”¨å·¥å…·çš„æ™ºèƒ½ä½“ï¼Œå¯ä»¥åšå¤šæ­¥æ¨ç†ã€‚

ä»¥ä¸‹æ˜¯æœ¬æ¬¡ä¼šè¯çš„å†å²å†…å®¹ï¼ˆç”¨æˆ·ä¹‹å‰è¯´è¿‡çš„è¯ï¼Œå¯èƒ½è¦å‚è€ƒï¼‰ï¼š
{history_text}

ä»¥ä¸‹æ˜¯ä½ ç›®å‰å·²ç»æ‹¿åˆ°çš„ä¸­é—´å·¥å…·ç»“æœï¼š
{context}

ç”¨æˆ·è¿™æ¬¡çš„æ–°ç›®æ ‡æ˜¯ï¼š
{user_input}

ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·æœ‰ï¼ˆåªèƒ½ä»ä¸‹é¢é€‰ï¼‰ï¼š
- multiply(a, b): è®¡ç®—ä¸¤ä¸ªæ•°å­—çš„ä¹˜ç§¯
- today(): è·å–ä»Šå¤©çš„æ—¥æœŸ
- praise(name): å¤¸å¥–å¥¶å¥¶

å¦‚æœä½ è§‰å¾—è¿˜éœ€è¦ç”¨å·¥å…·ï¼Œè¯·è¾“å‡ºä¸€ä¸ª JSONï¼ˆåªèƒ½è¾“å‡º JSONï¼‰ï¼š
{{
  "action": "tool",
  "tool": "<å·¥å…·å>",
  "args": {{...}}
}}

å¦‚æœä½ è§‰å¾—å·²ç»å¯ä»¥ç»™ç”¨æˆ·æœ€ç»ˆå›ç­”äº†ï¼Œè¯·è¾“å‡ºï¼š
{{
  "action": "finish",
  "final": "<ä½ è¦è¯´çš„å†…å®¹å¤§çº²>"
}}
åªèƒ½è¾“å‡º JSONï¼Œä¸èƒ½åŠ è§£é‡Šï¼Œä¹Ÿä¸è¦åŠ  ``` åŒ…è£¹ã€‚
"""

    # 6ï¸âƒ£ æœ€ç»ˆæ•´ç†æç¤º
    FINAL_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ¸©æŸ”çš„AIåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä¸‹é¢çš„ä¿¡æ¯ï¼Œç”Ÿæˆè¦è·Ÿå¥¶å¥¶è¯´çš„è¯ï¼Œè¯­æ°”æ¸©æŸ”ç®€çŸ­ã€‚

ç”¨æˆ·è¿™æ¬¡çš„è¯·æ±‚ï¼š
{user_input}

è¿™æ¬¡å¯¹è¯ä¸­ä½ å¾—åˆ°çš„å·¥å…·ç»“æœï¼š
{context}

è¿™ä½å¥¶å¥¶ä¹‹å‰è¯´è¿‡çš„è¯ï¼ˆå†å²ï¼‰ï¼š
{history_text}

è¯·å†™å‡ºæœ€ç»ˆå›ç­”ã€‚
"""

    # 7ï¸âƒ£ Agent ä¸»å¾ªç¯ï¼ˆå¤šæ­¥ + è®°å¿†ï¼‰
    def agent_run(user_input: str, session_id: str = "grandma-001", max_steps: int = 4) -> str:
        # 7.1 å–å‡ºè¿™ä½å¥¶å¥¶ä¹‹å‰çš„å¯¹è¯å†å²
        history_obj = get_history(session_id)
        if history_obj.messages:
            history_lines = []
            for msg in history_obj.messages:
                role = "ç”¨æˆ·" if msg.type == "human" else "AI"
                history_lines.append(f"{role}ï¼š{msg.content}")
            history_text = "\n".join(history_lines)
        else:
            history_text = "ï¼ˆæš‚æ— å†å²ï¼‰"

        # 7.2 æœ¬è½®çš„ä¸­é—´å·¥å…·ç»“æœ
        context = []

        for step in range(max_steps):
            print(f"\n--- ç¬¬ {step + 1} æ­¥æ€è€ƒ ---")

            context_text = "\n".join(context) if context else "ï¼ˆè¿˜æ²¡æœ‰å·¥å…·ç»“æœï¼‰"

            decide_input = DECIDE_PROMPT.format(
                history_text=history_text,
                context=context_text,
                user_input=user_input,
            )

            decide_resp = llm.invoke(decide_input)
            decide_text = decide_resp.content
            print("[æ¨¡å‹å†³ç­–è¾“å‡º]ï¼š", decide_text)

            clean = extract_json(decide_text)
            try:
                decide_obj = json.loads(clean)
            except json.JSONDecodeError:
                print("âŒ æ¨¡å‹æ²¡æŒ‰ JSON æ¥ï¼Œæå‰ç»“æŸã€‚åŸæ–‡æ˜¯ï¼š", decide_text)
                context.append("[é”™è¯¯] æ¨¡å‹è¾“å‡ºä¸æ˜¯åˆæ³• JSON")
                break

            action = decide_obj.get("action")

            if action == "finish":
                outline = decide_obj.get("final", "")
                context.append(f"[æ¨¡å‹æœ€ç»ˆå¤§çº²] {outline}")
                break

            if action == "tool":
                tool_name = decide_obj.get("tool")
                tool_args = decide_obj.get("args", {})
                if tool_name not in tools:
                    context.append(f"[é”™è¯¯] æ²¡æœ‰è¿™ä¸ªå·¥å…·ï¼š{tool_name}")
                    break

                tool_fn = tools[tool_name]
                if tool_args:
                    tool_result = tool_fn.invoke(tool_args)
                else:
                    tool_result = tool_fn.invoke({})
                print(f"[å·¥å…·æ‰§è¡Œç»“æœ] {tool_name} â†’ {tool_result}")
                context.append(f"[{tool_name}] {tool_result}")
            else:
                context.append(f"[é”™è¯¯] æœªçŸ¥åŠ¨ä½œï¼š{action}")
                break

        # 7.3 æœ€ç»ˆæ•´ç†
        final_input = FINAL_PROMPT.format(
            user_input=user_input,
            context="\n".join(context),
            history_text=history_text,
        )
        final_resp = llm.invoke(final_input)
        final_answer = final_resp.content

        # 7.4 æŠŠè¿™è½®çš„é—®ç­”å†™å›å†å²
        history_obj.add_user_message(user_input)
        history_obj.add_ai_message(final_answer)

        return final_answer

    # 8ï¸âƒ£ æ¨¡æ‹Ÿä¸¤è½®å¯¹è¯ï¼Œçœ‹çœ‹è®°ä¸è®°å¾—
    print("\n=== æ–¹å¼ä¹ï¼šæœ‰è®°å¿†çš„å¤šæ­¥ Agent ===")

    # ç¬¬1è½®ï¼šå…ˆå‘Šè¯‰å¥¹ä¿¡æ¯
    ans1 = agent_run("æˆ‘å«å¥¶å¥¶ï¼Œä»Šå¹´90å²ï¼Œä½åœ¨åŒ—äº¬ï¼Œæœ€è¿‘åœ¨å­¦AIã€‚")
    print("AIï¼ˆç¬¬1è½®ï¼‰ï¼š", ans1)

    # ç¬¬2è½®ï¼šè€ƒå®ƒè¿˜è®°ä¸è®°å¾—
    ans2 = agent_run("æˆ‘åˆšæ‰è¯´æˆ‘ä½å“ªæ¥ç€ï¼Ÿé¡ºä¾¿å†å¤¸å¤¸æˆ‘ï½")
    print("AIï¼ˆç¬¬2è½®ï¼‰ï¼š", ans2)







# =====================================================
# ğŸš€ ç¨‹åºå…¥å£
# =====================================================
if __name__ == "__main__":


    print("=== æ–¹å¼ä¸€ï¼šrequests ===")
    call_by_requests()

    print("\n=== æ–¹å¼äºŒï¼šLangChain ===")
    call_by_langchain()

    print("\n=== æ–¹å¼ä¸‰ï¼šLangChain + PromptTemplateï¼ˆç»“æ„åŒ–æç¤ºè¯ï¼‰ ===")
    call_by_langchain_prompt()

    print("\n=== æ–¹å¼å››ï¼šLangChain + PromptTemplate ï¼ˆç»“æ„åŒ–æç¤ºè¯ï¼‰+ Memory ===")
    call_with_memory()

    print("\n=== æ–¹å¼äº”ï¼šLangChain + Chainsï¼ˆä»»åŠ¡é“¾ï¼‰ ===")
    call_by_langchain_chains()

    print("\n=== æ–¹å¼å…­ï¼šLangChain + Chains + Memory ===")
    call_by_langchain_chains_with_memory()

    print("\n=== æ–¹å¼ä¸ƒï¼šLangChain Agentï¼ˆæ™ºèƒ½ä½“ï¼‰ ===")
    call_by_langchain_agent()

    print("\n=== æ–¹å¼å…«ï¼šLangChain Agentï¼ˆæ™ºèƒ½ä½“ï¼‰ ===")
    call_by_langchain_official_agent()

    print("\n=== æ–¹å¼ä¹ï¼šæœ‰è®°å¿†çš„å¤šæ­¥ Agent ===")
    call_by_langchain_agent_with_memory()